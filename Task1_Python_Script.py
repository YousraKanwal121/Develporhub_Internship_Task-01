# -*- coding: utf-8 -*-
"""Task1_python_Script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12lT92m0WaL4lCr_CRQPyck6Y2HZTn3fD
"""

from google.colab import files
uploaded = files.upload()
import pandas as pd
df = pd.read_csv('train_u6lujuX_CVtuZ9i (1).csv')
df.head(100)

df.shape

df.isnull()

df.isnull().sum()

df.isnull().sum().sum()

df2 = df.fillna(value = 0)
df2

df = df.fillna(method= 'bfill')
df

df

df3 = df.fillna({'Self_Employed': 'abcd',  'LoanAmount':'cdef','Credit_Hiatory': 'klmn' })
df3

df4 = df.dropna(how ='any')
df4

df

import numpy as np
df5 = df.replace(to_replace=np.nan,value= 7546)
df5

df.head(500)

df['LoanAmount'].isnull().sum()

df['LoanAmount'] = df['LoanAmount'].interpolate(method='linear', limit_direction='both')
df
df.head(100)

df['Loan_Status'].value_counts()

df['Credit_History'] = df['Credit_History'].interpolate(method='linear', limit_direction='both')
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].interpolate(method='linear', limit_direction='both')
df['Loan_Status'].value_counts()


df
df.head(500)

df['Loan_Status'] = df['Loan_Status'].map({'N':0, 'Y':1})
df['Loan_Status'] = df['Loan_Status'].fillna(0)  # ya 1, depend karta hai
df.head(10)

df['Married'].isnull().sum()

df['Married'] = df['Married'].fillna(df['Married'].mode()[0])
df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])
df['Dependents'] = df['Dependents'].fillna(df['Dependents'].mode()[0])
df['Self_Employed'] = df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])
df['Credit_History'] = df['Credit_History'].interpolate(method='linear', limit_direction='both')
df['Loan_Amount_Term'] = df['Loan_Amount_Term'].interpolate(method='linear', limit_direction='both')
df['LoanAmount'] = df['LoanAmount'].interpolate(method='linear', limit_direction='both')
df['Dependents'].isnull().sum()
df.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np




numeric_cols = df.select_dtypes(include='number').columns  # numeric columns select

for col in numeric_cols:
    plt.figure(figsize=(8,5))
    sns.histplot(df[col], bins=30, kde=True, color='skyblue')  # seaborn + matplotlib
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()
plt.savefig("loan_amount_plot.png")

"""# New Section"""

import matplotlib.patches
df['Gender'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Bar Plot of Gender')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

df['Married'].value_counts().plot(kind='bar', color='green')
plt.title('Bar Plot of Married')
plt.xlabel('Married status')
plt.ylabel('Count')
plt.show()

df['Education'].value_counts().plot(kind='bar', color='orange')
plt.title('Bar plot of Education')
plt.xlabel('Educated')
plt.ylabel('Count')
plt.show()

df['Property_Area'].value_counts().plot(kind='bar', color='pink')
plt.title('Bar Plot of Property')
plt.xlabel('Property status')
plt.ylabel('Count')
plt.show()

df['Loan_Status'].value_counts().plot(kind='bar', color='brown')
plt.title('Bar Plot of Loan_Status')
plt.xlabel('Loan_Status')
plt.ylabel('Count')
plt.show()

df.isnull().sum()

df('Education').unique

# 1. Strip column names
df.columns = df.columns.str.strip()

# 2. Robust safe_mode_fill function
def safe_mode_fill(col):
    # If column is fully NaN
    if col.dropna().empty:
        return col.fillna(0)   # or any default value
    # If mode exists
    elif not col.mode().empty:
        return col.fillna(col.mode()[0])
    else:
        return col.fillna(0)   # fallback

# 3. Fill categorical columns safely
categorical_cols = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']
for col in categorical_cols:
    if col in df.columns:
        df[col] = safe_mode_fill(df[col])

# 4. Convert strings to lowercase (only object columns)
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].str.lower()

# 5. Dependents fix
df['Dependents'] = df['Dependents'].replace('3+', 3).astype(int)

# 6. Map categorical columns to numeric
df['Gender'] = df['Gender'].map({'male':1, 'female':0})
df['Married'] = df['Married'].map({'yes':1, 'no':0})
df['Education'] = df['Education'].map({'graduate':1, 'not graduate':0})
df['Self_Employed'] = df['Self_Employed'].map({'yes':1, 'no':0})
df['Property_Area'] = df['Property_Area'].map({'urban':2, 'semiurban':1, 'rural':0})
df['Loan_Status'] = df['Loan_Status'].map({'y':1, 'n':0})
df['Gender'] = df['Gender'].fillna(0)
df['Married'] = df['Married'].fillna(0)
df['Education'] = df['Education'].fillna(0)
df['Self_Employed'] = df['Self_Employed'].fillna(0)
df['Property_Area'] = df['Property_Area'].fillna(0)
df['Loan_Status'] = df['Loan_Status'].fillna(0)

# Dependents fix
df['Dependents'] = df['Dependents'].replace('3+', 3).fillna(0).astype(int)

# Map categorical (optional now because already filled with 0/1)
df['Gender'] = df['Gender'].map({'male':1, 'female':0}).fillna(0).astype(int)
df['Married'] = df['Married'].map({'yes':1, 'no':0}).fillna(0).astype(int)
df['Education'] = df['Education'].map({'graduate':1, 'not graduate':0}).fillna(0).astype(int)
df['Self_Employed'] = df['Self_Employed'].map({'yes':1, 'no':0}).fillna(0).astype(int)
df['Property_Area'] = df['Property_Area'].map({'urban':2, 'semiurban':1, 'rural':0}).fillna(0).astype(int)
df['Loan_Status'] = df['Loan_Status'].map({'y':1, 'n':0}).fillna(0).astype(int)

# 7. Check
print(df.head())
print(df.isnull().sum())

df = pd.read_csv('/content/loan.csv')

df['Loan_Status'] = df['Loan_Status'].map({'N':0, 'Y':1})
df['Loan_Status'] = df['Loan_Status'].fillna(0)  # ya 1, depend karta hai
df.head(10)

df = pd.read_csv('train_u6lujuX_CVtuZ9i (1).csv')
df['Loan_Status'].value_counts()
df['Loan_Status'] = df['Loan_Status'].map({'Y':1, 'N':0})
df['Loan_Status'].value_counts()
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for col in df.select_dtypes(include=['object']).columns:
    df[col] = le.fit_transform(df[col].astype(str))


df.head()

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression

# Label Encoding
le = LabelEncoder()
for col in cat_cols:
    X[col] = le.fit_transform(X[col].astype(str))

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

# Logistic Regression + GridSearchCV
classifier = LogisticRegression(max_iter=5000)  # max_iter increase

param_grid = [
    {'penalty': ['l1', 'l2'], 'C': [1,2,3,4,5,6], 'solver': ['saga']},
    {'penalty': ['elasticnet'], 'C': [1,2,3,4,5,6], 'solver': ['saga'], 'l1_ratio':[0,0.5,1]}
]

grid = GridSearchCV(classifier, param_grid=param_grid, scoring='accuracy', cv=5)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best Score:", grid.best_score_)

# Best score from GridSearchCV
print(grid.best_score_)

# Predictions using the correct test set
y_pred = grid.predict(X_test)  # Uppercase X

# Accuracy & classification report
from sklearn.metrics import accuracy_score, classification_report
score = accuracy_score(y_test, y_pred)  # y_test first, y_pred second
print("Accuracy:", score)

print("Classification Report:\n", classification_report(y_test, y_pred))
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
y_pred = grid.predict(X_test)

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
y_pred = grid.predict(X_test)

# 2. Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# 3. Plot heatmap
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['Not Approved', 'Approved'],
            yticklabels=['Not Approved', 'Approved'],
            cmap="Blues")
plt.ylabel('Actual', fontsize=13)
plt.xlabel('Predicted', fontsize=13)
plt.title('Confusion Matrix', fontsize=17, pad=20)
plt.gca().xaxis.set_label_position('top')
plt.gca().xaxis.tick_top()
plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)
plt.show()





# 1. Define features & target
X = df.drop(['Loan_ID','Loan_Status'], axis=1)
y = df['Loan_Status']

# 2. Fill NaNs in numeric columns
numeric_cols = X.select_dtypes(include=['float64','int64']).columns
X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())

# 3. Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Logistic Regression + GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

classifier = LogisticRegression(max_iter=1000)

parameter = {
    'penalty': ['l1', 'l2', 'elasticnet'],
    'C': [1, 2, 3, 4, 5, 6],
    'solver': ['saga'],
    'l1_ratio': [0, 0.5, 1]  # only for elasticnet
}

grid = GridSearchCV(classifier, param_grid=parameter, scoring='accuracy', cv=5)
grid.fit(X_train, y_train)

print("Best Parameters:", grid.best_params_)
print("Best Score:", grid.best_score_)